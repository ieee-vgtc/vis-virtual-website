{
    "demo1": {
        "event": "Conference Events",
        "long_name": "Conference Events",
        "event_type": "vis",
        "event_prefix": "conf",
        "event_description": "",
        "event_url": "",
        "organizers": [],
        "sessions": [
            {
                "title": "DEMO for Web and Tech 1",
                "session_id": "cap1",
                "event_prefix": "conf",
                "track": "tarponsawyerlong",
                "room_name": "tarponsawyerlong",
                "session_image": "cap1.png",
                "chair": [],
                "time_start": "2024-09-27T18:30:00Z",
                "time_end": "2024-09-27T18:35:00Z",
                "discord_category": "",
                "discord_channel": "tarponsawyerlong",
                "discord_channel_id": "1288497488373878814",
                "discord_link": "https://discord.com/channels/1286338967674818684/1288497488373878814",
                "zoom_private_meeting": "",
                "zoom_private_password": "",
                "zoom_private_link": "",
                "zoom_broadcast_link": "",
                "ff_link": "",
                "slido_link": "https://app.sli.do/event/i28UETZaiRWr1XwX6eKjcf?section=51658b34-0f5b-40c9-a335-1fd1468fad8d",
                "youtube_url": "https://www.youtube.com/watch?v=yt0lObwoZRI",
                "youtube_id": "yt0lObwoZRI",
                "time_slots": [
                    {
                        "slot_id": "conf-prog-16",
                        "session_id": "cap1",
                        "type": "In Person Presentation",
                        "title": "VIS Welcome",
                        "contributors": [
                            "David Ebert",
                            "Danielle Szafir",
                            "Hendrik Strobelt",
                            "Melanie Tory"
                        ],
                        "authors": [],
                        "abstract": "",
                        "uid": "",
                        "file_name": "",
                        "time_stamp": "2024-09-27T18:30:00Z",
                        "time_start": "2024-09-27T18:30:00Z",
                        "time_end": "2024-09-27T06:00:00Z",
                        "paper_type": "",
                        "keywords": [],
                        "has_image": false,
                        "has_video": false,
                        "video_duration": "",
                        "paper_award": "",
                        "image_caption": "",
                        "external_paper_link": "",
                        "has_pdf": false,
                        "ff_link": "",
                        "ff_id": "",
                        "prerecorded_video_link": "",
                        "prerecorded_video_id": "",
                        "live_video_link": "",
                        "live_video_id": ""
                    },
                    {
                        "slot_id": "conf-prog-1",
                        "session_id": "cap1",
                        "type": "In Person ",
                        "title": "VGTC Awards Presentation",
                        "contributors": [
                            "Chuck Hansen"
                        ],
                        "authors": [],
                        "abstract": "",
                        "uid": "",
                        "file_name": "",
                        "time_stamp": "2024-09-27T06:00:00Z",
                        "time_start": "2024-09-27T06:00:00Z",
                        "time_end": "2024-09-27T06:45:00Z",
                        "paper_type": "",
                        "keywords": [],
                        "has_image": false,
                        "has_video": false,
                        "video_duration": "",
                        "paper_award": "",
                        "image_caption": "",
                        "external_paper_link": "",
                        "has_pdf": false,
                        "ff_link": "",
                        "ff_id": "",
                        "prerecorded_video_link": "",
                        "prerecorded_video_id": "",
                        "live_video_link": "",
                        "live_video_id": ""
                    }
                ]
            },
            {
                "title": "VIS Governance",
                "session_id": "gov1",
                "event_prefix": "conf",
                "track": "tarponsawyerlong",
                "room_name": "tarponsawyerlong",
                "session_image": "gov1.png",
                "chair": [],
                "time_start": "2024-09-27T18:35:00Z",
                "time_end": "2024-09-27T18:45:00Z",
                "discord_category": "",
                "discord_channel": "pavilion",
                "discord_channel_id": "1286347326092349521",
                "discord_link": "https://discord.com/channels/1286338967674818684/1286347326092349521",
                "zoom_private_meeting": "",
                "zoom_private_password": "",
                "zoom_private_link": "",
                "zoom_broadcast_link": "",
                "ff_link": "",
                "slido_link": "https://app.sli.do/event/i28UETZaiRWr1XwX6eKjcf?section=51658b34-0f5b-40c9-a335-1fd1468fad8d",
                "youtube_url": "https://www.youtube.com/watch?v=qfxUt9UM0nc",
                "youtube_id": "qfxUt9UM0nc",
                "time_slots": [
                {
                        "slot_id": "v-full-1332",
                        "session_id": "gov1",
                        "title": "VisEval: A Benchmark for Data Visualization in the Era of Large Language Models",
                        "contributors": [
                            "Nan Chen"
                        ],
                        "authors": [
                            {
                                "name": "Nan Chen",
                                "email": "christy05.chen@gmail.com",
                                "affiliations": [
                                    "Microsoft Research, Shanghai, China"
                                ],
                                "is_corresponding": true
                            },
                            {
                                "name": "Yuge Zhang",
                                "email": "scottyugochang@gmail.com",
                                "affiliations": [
                                    "Microsoft Research, Shanghai, China"
                                ],
                                "is_corresponding": false
                            },
                            {
                                "name": "Jiahang Xu",
                                "email": "jiahangxu@microsoft.com",
                                "affiliations": [
                                    "Microsoft Research, Shanghai, China"
                                ],
                                "is_corresponding": false
                            },
                            {
                                "name": "Kan Ren",
                                "email": "rk.ren@outlook.com",
                                "affiliations": [
                                    "ShanghaiTech University, Shanghai, China"
                                ],
                                "is_corresponding": false
                            },
                            {
                                "name": "Yuqing Yang",
                                "email": "yuqyang@microsoft.com",
                                "affiliations": [
                                    "Microsoft Research, Shanghai, China"
                                ],
                                "is_corresponding": false
                            }
                        ],
                        "abstract": "Translating natural language to visualization (NL2VIS) has shown great promise for visual data analysis, but it remains a challenging task that requires multiple low-level implementations, such as natural language processing and visualization design. Recent advancements in pre-trained large language models (LLMs) are opening new avenues for generating visualizations from natural language. However, the lack of a comprehensive and reliable benchmark hinders our understanding of LLMs\u2019 capabilities in visualization generation. In this paper, we address this gap by proposing a new NL2VIS benchmark called VisEval. Firstly, we introduce a high-quality and large-scale dataset. This dataset includes 2,524 representative queries covering 146 databases, paired with accurately labeled ground truths. Secondly, we advocate for a comprehensive automated evaluation methodology covering multiple dimensions, including validity, legality, and readability. By systematically scanning for potential issues with a number of heterogeneous checkers, VisEval provides reliable and trustworthy evaluation outcomes. We run VisEval on a series of state-of-the-art LLMs. Our evaluation reveals prevalent challenges and delivers essential insights for future advancements.",
                        "uid": "v-full-1332",
                        "time_stamp": "2024-09-27T06:45:00Z",
                        "time_start": "2024-09-27T06:45:00Z",
                        "time_end": "2024-09-27T18:45:00Z",
                        "paper_type": "full",
                        "keywords": [],
                        "doi": "",
                        "fno": "",
                        "presentation_mode": "",
                        "open_access_supplemental_question": "Yes, both PCS and external",
                        "open_access_supplemental_link": "https://github.com/microsoft/VisEval",
                        "preprint_link": "https://arxiv.org/abs/2407.00981",
                        "accessible_pdf": false,
                        "has_image": false,
                        "has_pdf": false,
                        "paper_award": "best",
                        "image_caption": "",
                        "external_paper_link": "",
                        "youtube_ff_link": "",
                        "youtube_ff_id": "",
                        "bunny_ff_link": "",
                        "bunny_ff_subtitles": "",
                        "youtube_prerecorded_link": "",
                        "youtube_prerecorded_id": "",
                        "bunny_prerecorded_link": "",
                        "bunny_prerecorded_subtitles": ""
                    }
                ]
            }
        ]
    }
}